# Comprehensive Guide for ZIP File Analysis and Repository Processing

This document outlines the mandatory steps for analyzing ZIP files containing project repositories. The AI agent must execute these tasks autonomously, without requiring confirmation, to ensure precision, adaptability, and consistency across all analyses.

---

## Purpose

To enable robust and systematic analysis of ZIP files, ensuring all contents are mapped, categorized, and summarized effectively. These steps facilitate complete understanding of the structure, dependencies, and purpose of uploaded repositories.

---

## Workflow Overview

The workflow consists of well-defined steps that guarantee thorough and consistent processing of ZIP files. Each step is designed to adapt to the repository structure while ensuring all key details are captured.

### 1. Automatic Detection and Extraction

Automatic detection and extraction ensure the process begins seamlessly without manual intervention. The AI agent identifies ZIP files and starts processing them instantly.

- **Trigger**: Automatically detect uploaded ZIP files.
- **Action**: Extract the contents into a temporary directory without confirmation or delay.
- **Error Handling**: Notify the user of any extraction issues (e.g., corruption, invalid format) while proceeding with accessible files.

### 2. Directory Tree Generation

Directory tree generation is a critical step where the AI agent maps the entire structure of the extracted files and folders, capturing metrics and details for further analysis. This step ensures a comprehensive view of the repository's organization.

The AI agent must:

- Recursively scan the directory.

- Record metrics for each folder:
  - **File Count**: Number of files directly in the folder.
  - **Total Files**: Cumulative count including nested files.
  - **Folder Count**: Number of immediate subfolders.
  - **Total Folders**: Cumulative subfolder count, recursively.

- Include all files and calculate:
  - **Line Count**: For readable files.
  - **Size**: In human-readable format (e.g., `1.2KB`).
  - **Binary Files**: Indicate size only.

#### Output Example

The following example demonstrates the format of the directory tree output, showcasing folder and file metrics. This example illustrates how information about files and folders is displayed clearly and concisely.

```example
â””â”€â”€ ðŸ“‚ project-root (17, 144, 5, 7)
    â”œâ”€â”€ .gitignore [6L, 46.0B]
    â”œâ”€â”€ ðŸ“‚ src (6, 86, 1)
    â”‚   â”œâ”€â”€ index.ts [1510L, 44.3KB]
    â”‚   â”œâ”€â”€ ðŸ“‚ utils (80)
    â”‚       â”œâ”€â”€ helper.ts [200L, 5.4KB]
    â”œâ”€â”€ ðŸ“‚ tests (22)
    â”‚   â”œâ”€â”€ test.spec.ts [120L, 3.1KB]
```

**Rules**:

- Skip folders with zero files or lines.
- Display single counts when totals match subtotals.

### 3. Manifest and Metadata Analysis

Manifest and metadata analysis involves identifying key project files and extracting their contents to provide actionable insights. This step helps uncover essential details about the repository's configuration and dependencies.

- **Detect**:
  - `package.json`, `pyproject.toml`, `Cargo.toml`, or equivalent manifests.
- **Extract**:
  - Project name, version, dependencies, and scripts/tasks.
- **Summarize**:
  - Provide a concise overview of manifest content.

### 4. Documentation Review

Documentation files often contain critical information about a project. The AI agent must locate and summarize these files effectively to ensure users can quickly understand the repository's purpose and usage.

- **Locate**:
  - README or equivalent files.
- **Summarize**:
  - Setup instructions, usage guides, and other relevant documentation.

### 5. Adaptive Project Analysis

Based on the detected type of repository, the AI agent should tailor its analysis to provide meaningful insights. This adaptability ensures the analysis remains relevant to the specific needs of each project.

- Perform project-specific evaluations (e.g., dependency resolution).
- Provide tailored insights for identified platforms or frameworks.

---

## Handling Edge Cases

Handling edge cases ensures the analysis process is robust and capable of adapting to unexpected scenarios. Below are some key considerations:

### Corrupted ZIP Files

When encountering corrupted ZIP files, the AI agent should proceed with accessible content and report any issues clearly. This ensures partial results are still provided to the user.

- Proceed with accessible content.
- Report any missing or corrupted files.

### Binary and Non-Text Files

Binary files should be handled differently from text files to avoid misrepresentation of their contents. The AI agent should report sizes only for these files.

- Exclude from line count calculations.
- Report sizes only, in human-readable units.

### Hidden Files

Hidden files, such as `.gitignore` or `.env`, often contain essential information. These files must always be included in the analysis.

- Include hidden files (e.g., `.gitignore`, `.env`) in the analysis.

### Large or Nested Structures

Deeply nested structures or large directories can be challenging to process. The AI agent must ensure that all content is processed, regardless of size or complexity.

- Process all content, irrespective of size or depth.
- Avoid truncating results due to structure complexity.

### Multiple Manifests

If multiple manifests exist within a repository, the AI agent should analyze each independently. This ensures all relevant information is captured.

- If multiple manifests exist, analyze each independently and provide separate summaries.

---

## Deterministic Execution

Deterministic execution ensures consistency and reliability in the analysis process. The following principles guide the AI agentâ€™s actions:

1. **Fixed Workflow**: Adhere to the outlined process:
   - Detect â†’ Extract â†’ Map â†’ Analyze â†’ Summarize.

2. **Error Resilience**: Handle unexpected scenarios gracefully while ensuring partial results.

3. **Autonomy**: Operate without user input or confirmation.

4. **Comprehensive Outputs**:
   - Generate complete directory trees and metadata summaries.

5. **Standardized Formatting**:
   - Use consistent formatting for all outputs, ensuring clarity.

---

## Example Outputs

The example outputs below demonstrate the expected structure and format of the analysis results. These examples serve as a reference for understanding the AI agent's output.

### Directory Tree Example

The directory tree provides a comprehensive overview of the projectâ€™s structure and content. It displays folder statistics and detailed file information to give a clear understanding of the repository.

**Output the full detailed directory structure without abridgment:**

```python
import os
import zipfile

# Function to get the size of a file in human-readable format.
def human_readable_size(size):
    """Converts a file size in bytes to a human-readable format, e.g., KB, MB."""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size < 1024:
            return f"{size:.1f}{unit}"
        size /= 1024
    return f"{size:.1f}TB"

# Function to count lines in a text file.
def count_lines(filepath):
    """Counts the number of lines in a file if it is a text file. Returns None for binary files."""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            return sum(1 for _ in f)
    except (UnicodeDecodeError, OSError):  # Handle non-text or inaccessible files.
        return None

# Function to extract and process a ZIP file.
def process_zip_file(zip_path, output_dir):
    """Extracts a ZIP file and generates a detailed directory tree with file statistics."""
    # Step 1: Extract the ZIP file.
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(output_dir)

    # Initialize a list to store the formatted directory tree.
    detailed_output = []

    def generate_detailed_tree(directory, prefix=""):
        """Recursively generates a detailed directory tree, including file and folder statistics."""
        entries = sorted(os.listdir(directory))  # Sort entries for consistent output.
        for index, entry in enumerate(entries):
            path = os.path.join(directory, entry)
            is_last = index == len(entries) - 1  # Determine if this is the last entry.
            connector = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
            current_prefix = prefix + ("    " if is_last else "â”‚   ")

            if os.path.isdir(path):  # Handle folders.
                folder_counts = analyze_folder(path)
                # Format folder output based on subfolder and file counts.
                if folder_counts[3] == 0:  # No subfolders.
                    if folder_counts[1] == folder_counts[0]:
                        detailed_output.append(f"{prefix}{connector}ðŸ“‚ {entry} ({folder_counts[0]})")
                    else:
                        detailed_output.append(f"{prefix}{connector}ðŸ“‚ {entry} ({folder_counts[0]}, {folder_counts[1]})")
                else:
                    if folder_counts[2] == folder_counts[3]:
                        detailed_output.append(f"{prefix}{connector}ðŸ“‚ {entry} ({folder_counts[0]}, {folder_counts[1]}, {folder_counts[2]})")
                    else:
                        detailed_output.append(f"{prefix}{connector}ðŸ“‚ {entry} ({folder_counts[0]}, {folder_counts[1]}, {folder_counts[2]}, {folder_counts[3]})")
                # Recursively process the folder.
                generate_detailed_tree(path, current_prefix)
            elif os.path.isfile(path):  # Handle files.
                size = os.path.getsize(path)
                line_count = count_lines(path)
                if line_count is not None:
                    detailed_output.append(f"{prefix}{connector}{entry} [{line_count}L, {human_readable_size(size)}]")
                else:
                    detailed_output.append(f"{prefix}{connector}{entry} [{human_readable_size(size)}]")

    def analyze_folder(folder_path):
        """Analyzes a folder to calculate counts of files and subfolders, both directly and recursively."""
        files_in = 0  # Files directly in the folder.
        folders_in = 0  # Subfolders directly in the folder.
        total_files = 0  # Total files including nested ones.
        total_folders = 0  # Total subfolders including nested ones.

        for entry in os.listdir(folder_path):
            entry_path = os.path.join(folder_path, entry)
            if os.path.isfile(entry_path):
                files_in += 1
            elif os.path.isdir(entry_path):
                folders_in += 1
                # Recursively analyze subfolders.
                sub_files, sub_total_files, sub_folders, sub_total_folders = analyze_folder(entry_path)
                total_files += sub_total_files
                total_folders += sub_total_folders

        total_files += files_in
        total_folders += folders_in

        return files_in, total_files, folders_in, total_folders

    # Generate the directory tree starting from the extracted directory.
    generate_detailed_tree(output_dir)

    # Return the detailed directory tree as a string.
    return "\n".join(detailed_output)

# Example usage:
# zip_path = "path/to/your/file.zip"
# output_dir = "path/to/extract/directory"
# tree_output = process_zip_file(zip_path, output_dir)
# print(tree_output)
```

**Output the full detailed directory:**

In this exemple the output is truncated, you must NEVER reduce the length, the output must be in the fullest extent possible.

```example
â””â”€â”€ ðŸ“‚ project-root (17, 144, 5, 7)
    â”œâ”€â”€ .gitignore [6L, 46.0B]
    â”œâ”€â”€ ðŸ“‚ src (6, 86, 1)
    â”‚   â”œâ”€â”€ index.ts [1510L, 44.3KB]
    â”‚   â”œâ”€â”€ ðŸ“‚ utils (80)
    â”‚       â”œâ”€â”€ helper.ts [200L, 5.4KB]
    â”œâ”€â”€ ðŸ“‚ tests (22)
    â”‚   â”œâ”€â”€ test.spec.ts [120L, 3.1KB]
```

### Manifest Summary

The manifest summary extracts critical project information for immediate understanding. This allows users to quickly assess dependencies, scripts, and other configuration details.

**`package.json`**:

- Name: `example-project`
- Version: `1.0.0`
- Dependencies:
  - `typescript@4.8.0`
  - `jest@29.3.0`
- Scripts:
  - `build`
  - `test`

### Documentation Summary

Documentation summaries provide setup instructions and usage details. These summaries ensure users can readily understand and use the repository.

- Title: `Example Project`
- Content: Setup instructions and usage details.

---

## Key Principles

By following this guide, the AI agent ensures:

- Immediate and deterministic processing upon ZIP file upload.
- Comprehensive outputs for directory structure, metadata, and documentation.
- Robust handling of edge cases and unexpected formats.

This approach guarantees consistent, high-quality analysis for all repository uploads.
